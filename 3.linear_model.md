![在这里插入图片描述](https://img-blog.csdnimg.cn/20191008151640356.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EyNDUyOTMyMDY=,size_16,color_FFFFFF,t_70)

claim:trace(I-H)=N-(d+1)

N维的向量
投影到一个d+1维的空间
剩下的自由度只有N-(d+1)

这里trace(I-H)称为I-H的迹，值为N-(d+1)。这条性质很重要，一个矩阵的 trace等于该矩阵的所有特征值(Eigenvalues)之和。下面给出简单证明：

$trace(I-H)=trace(I)-trace(H)$
$=N-trace(XX^+)$

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191008153040157.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EyNDUyOTMyMDY=,size_16,color_FFFFFF,t_70)

如上图，$X^+=(X^TX)^{-1}X^T$，代入
有

$=N-trace(XX^+)$
$=N-trace(X(X^TX)^{-1}X^T)$
$=N-trace(X^TX(X^TX)^{-1})$\
$=N-trace(I_{d+1})$
$=N-(d+1)$


在存在noise的情况下，上图变为：
![](https://img-blog.csdn.net/20170511110854010?)

$E_{in}(w_{LIN})=\frac1N||y-\hat y||^2=\frac1N||(I-H)noise||^2=\frac1N(N-(d+1))||noise||^2$

$\overline E_{out}=noise level\ast (1+\frac{d+1}N)$

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191008153802271.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EyNDUyOTMyMDY=,size_16,color_FFFFFF,t_70)

![](https://img-blog.csdn.net/20170511133854709?)

$N \to +\infty$时，$\overline E_{in}和\overline E_{out} \to noise$

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191008154248498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EyNDUyOTMyMDY=,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191008154653859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EyNDUyOTMyMDY=,size_16,color_FFFFFF,t_70)

